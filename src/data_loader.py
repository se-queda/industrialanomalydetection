import os
import tensorflow as tf

IMG_SIZE = 256
CHANNELS = 3
AUTOTUNE = tf.data.AUTOTUNE


def collect_image_paths(root_dir, mode="train", categories=None):
    data = []
    if categories is None:
        categories = os.listdir(root_dir)

    for category in categories:
        folder = os.path.join(root_dir, category)

        if mode == "train":
            img_dir = os.path.join(folder, 'train', 'good')
            for fname in os.listdir(img_dir):
                img_path = os.path.join(img_dir, fname)
                data.append((img_path, 0))

        elif mode == "test":
            test_dir = os.path.join(folder, 'test')
            for subfolder in os.listdir(test_dir):
                defect_dir = os.path.join(test_dir, subfolder)
                if not os.path.isdir(defect_dir):
                    continue
                label = 0 if subfolder == "good" else 1
                for fname in os.listdir(defect_dir):
                    img_path = os.path.join(defect_dir, fname)
                    data.append((img_path, label))

        print(f"[DEBUG] Collected {len(data)} samples for category '{category}' in mode '{mode}'")
    return data


def image_parser(image_path, label):
    img = tf.io.read_file(image_path)
    img = tf.image.decode_image(img, channels=CHANNELS, expand_animations=False)
    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE])
    img = tf.cast(img, tf.float32) / 127.5 - 1.0  # Normalize to [-1, 1]
    return img, label


def augmentor(image, label):
    image = tf.image.random_flip_left_right(image)
    image = tf.image.random_brightness(image, max_delta=0.1)
    image = tf.image.random_contrast(image, lower=0.9, upper=1.1)
    image = tf.image.adjust_jpeg_quality(
        image, jpeg_quality=tf.random.uniform([], 90, 100, dtype=tf.int32)
    )
    image = tf.clip_by_value(image, -1.0, 1.0)
    return image, label


def get_dataset(root_dir, categories=None, mode="train", augment=False, batch_size=32, cache=False):
    samples = collect_image_paths(root_dir, mode, categories)
    paths, labels = zip(*samples)

    ds = tf.data.Dataset.from_tensor_slices((list(paths), list(labels)))

    # ðŸ‘‡ Parallel image decoding
    ds = ds.map(image_parser, num_parallel_calls=AUTOTUNE)

    # ðŸ‘‡ Data augmentation (if training mode and requested)
    if augment and mode == "train":
        ds = ds.map(augmentor, num_parallel_calls=AUTOTUNE)

    ds = ds.cache()
    #ds = ds.shuffle(buffer_size=4096)
    ds = ds.batch(batch_size)
    ds = ds.prefetch(AUTOTUNE)

    return ds